{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6guqhQADTU83"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Read HDFS CSV\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUfSOWGuTXsM"
      },
      "outputs": [],
      "source": [
        "customers = spark.read.csv(\"hdfs://namenode:9000/raw/telco_customer_churn.csv\",\n",
        "                    header=True, inferSchema=True)\n",
        "complaints = spark.read.csv(\"hdfs://namenode:9000/raw/complaints.csv\",\n",
        "                            header=True, inferSchema=True)\n",
        "payments = spark.read.csv(\"hdfs://namenode:9000/raw/payments.csv\",\n",
        "                          header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7Uv4hVZTXxe"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col, sum, when\n",
        "\n",
        "# -----------------------------\n",
        "def count_nulls(df, df_name):\n",
        "    print(f\"\\nNulls count in {df_name}:\")\n",
        "    df.select([sum(when(col(c).isNull(), 1).otherwise(0)).alias(c) for c in df.columns]).show()\n",
        "\n",
        "count_nulls(churn_df, \"Churn\")\n",
        "count_nulls(payments_df, \"Payments\")\n",
        "count_nulls(tickets_df, \"Tickets\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIEuxpQQTX02"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col,sum,when\n",
        "\n",
        "def count_nulls(df,df_name):\n",
        "    print(f\"\\n Nulls count in {df_name}:\")\n",
        "    df.select([sum(when(col(c).isNull(),1).otherwise(0)).alias(c) for c in df.columns]).show()\n",
        "\n",
        "count_nulls(customers,\"customer churn\")\n",
        "count_nulls(payments,\"payments\")\n",
        "count_nulls(complaints,\"complaints\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxqrkcEGTX4L"
      },
      "outputs": [],
      "source": [
        "customers.select([sum(when(col(c).isNull(), 1).otherwise(0)).alias(c) for c in customers.columns]).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxa3tLsGTX7K"
      },
      "outputs": [],
      "source": [
        "#working with 2 columns churn category and churn reason:\n",
        "#they're null because no customers churn the service, and then fill with \"not churned\"\n",
        "#------------Fill-------------\n",
        "customers = customers.withColumn(\"Churn Category\",\n",
        "    when(col(\"Churn Category\").isNull(), \"Not Churned\").otherwise(col(\"Churn Category\"))).withColumn(\n",
        "    \"Churn Reason\",when(col(\"Churn Reason\").isNull(), \"Not Churned\").otherwise(col(\"Churn Reason\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3M4Ayj4yTX-V"
      },
      "outputs": [],
      "source": [
        "#working with internet type and see nulls maybe not subscribe to internet.\n",
        "#fill it with \"no internet\"\n",
        "#-----------Fill----------\n",
        "customers = customers.withColumn(\"Internet Type\",when(col(\"Internet Type\").isNull(), \"No Internet\").otherwise(col(\"Internet Type\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixyvrHU0TYBn"
      },
      "outputs": [],
      "source": [
        "#working with offer and see nulls maybe no offer for them\n",
        "#fill it with \"No Offer\"\n",
        "customers = customers.withColumn(\"Offer\", when(col(\"Offer\").isNull(),\"No Offer\").otherwise(col(\"Offer\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQVSQCHITYEs"
      },
      "outputs": [],
      "source": [
        "#Check no nulls\n",
        "customers.select([sum(when(col(c).isNull(),1).otherwise(0)).alias(c) for c in [\"Churn Category\", \"Churn Reason\",\"Internet Type\",\"Offer\"]]).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EE1oLNJvTYHl"
      },
      "outputs": [],
      "source": [
        "customers.groupBy(\"Offer\").count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wN_gmVSHTYKa"
      },
      "outputs": [],
      "source": [
        "#As we can see, alot of Customers haven't any num of referrals that's cause to don't get offer\n",
        "customers.filter((col(\"Offer\") == \"No Offer\") & (col(\"Number of Referrals\") == 0))\\\n",
        "        .select(\"Customer ID\", \"Number of Referrals\", \"Offer\").show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7KwG4U-TYNt"
      },
      "outputs": [],
      "source": [
        "customers.groupBy(\"Internet Type\").count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nADJ2CibTYRI"
      },
      "outputs": [],
      "source": [
        "#As we can see, the null values in \"Internet Type\" don't have internet, so I pass them to \"No Internet\"\n",
        "no_internet_df = customers.filter(col(\"Internet Type\") == \"No Internet\")\n",
        "no_internet_df.groupBy(\"Internet Service\").count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g31-6UQMTYT6"
      },
      "outputs": [],
      "source": [
        "def check_duplicates(df, df_name):\n",
        "    total_rows = df.count()\n",
        "    distinct_rows = df.dropDuplicates().count()\n",
        "    duplicates = total_rows - distinct_rows\n",
        "    print(f\"{df_name} has {duplicates} duplicate rows.\")\n",
        "\n",
        "check_duplicates(customers, \"Customers\")\n",
        "check_duplicates(payments,\"Payments\")\n",
        "check_duplicates(complaints,\"Complaints\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_xwrz6qTYXV"
      },
      "outputs": [],
      "source": [
        "#Check randomly columns for Consistency\n",
        "customers.select(\"Churn\").distinct().show()\n",
        "payments.select(\"PaymentStatus\").distinct().show()\n",
        "complaints.select(\"Status\").distinct().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vk-5xQHWTYaw"
      },
      "outputs": [],
      "source": [
        "#Create DWH\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, to_date, year, month, dayofmonth\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Churn_DWH\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPARO5eDTYeE"
      },
      "outputs": [],
      "source": [
        "dim_customers = customers.select(\n",
        "    \"Customer ID\", \"Age\", \"Gender\", \"City\", \"State\", \"Country\",\n",
        "    \"Married\", \"Dependents\", \"Device Protection Plan\", \"Internet Service\",\n",
        "    \"Internet Type\", \"Contract\", \"Payment Method\", \"Churn\", \"Churn Category\"\n",
        ").withColumnRenamed(\"Customer ID\", \"CustomerID\")\n",
        "\n",
        "dim_customers.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IudeRoVITYhG"
      },
      "outputs": [],
      "source": [
        "all_dates = payments.select(col(\"InvoiceDate\").alias(\"date\")).union(\n",
        "    complaints.select(col(\"DateOpened\").alias(\"date\"))\n",
        ").distinct()\n",
        "\n",
        "dim_time = all_dates.withColumn(\"date\", to_date(\"date\", \"yyyy-MM-dd\")) \\\n",
        "    .withColumn(\"year\", year(\"date\")) \\\n",
        "    .withColumn(\"month\", month(\"date\")) \\\n",
        "    .withColumn(\"day\", dayofmonth(\"date\"))\n",
        "\n",
        "dim_time.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xf0Y6JKcTYkC"
      },
      "outputs": [],
      "source": [
        "fact_payments = payments.select(\n",
        "    col(\"PaymentID\").alias(\"PaymentID\"),\n",
        "    col(\"customerID\").alias(\"CustomerID\"),\n",
        "    col(\"InvoiceDate\").alias(\"date\"),\n",
        "    col(\"AmountDue\").cast(\"double\"),\n",
        "    col(\"AmountPaid\").cast(\"double\"),\n",
        "    col(\"PaymentStatus\"),\n",
        "    col(\"DelayDays\").cast(\"int\")\n",
        ")\n",
        "\n",
        "fact_payments.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_M9ROKHTYnc"
      },
      "outputs": [],
      "source": [
        "fact_complaints = complaints.select(\n",
        "    col(\"TicketID\").alias(\"TicketID\"),\n",
        "    col(\"customerID\").alias(\"CustomerID\"),\n",
        "    col(\"DateOpened\").alias(\"date\"),\n",
        "    col(\"Category\"),\n",
        "    col(\"ResolutionTime_Days\").cast(\"int\"),\n",
        "    col(\"Status\")\n",
        ")\n",
        "\n",
        "fact_complaints.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8c9q2n-alY-G"
      },
      "outputs": [],
      "source": [
        "# SK --> for Dim\n",
        "from pyspark.sql.functions import monotonically_increasing_id\n",
        "\n",
        "dim_customers = dim_customers.withColumn(\"customer_sk\", monotonically_increasing_id())\n",
        "\n",
        "dim_time = dim_time.withColumn(\"time_sk\", monotonically_increasing_id())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7pbChGYlZ8y"
      },
      "outputs": [],
      "source": [
        "fact_payments_dw = fact_payments.join(\n",
        "    dim_customers.select(\"customer_sk\", \"CustomerID\"),\n",
        "    fact_payments.CustomerID == dim_customers.CustomerID,\n",
        "    how=\"left\"\n",
        ")\n",
        "fact_payments_dw = fact_payments_dw.join(\n",
        "    dim_time.withColumnRenamed(\"date\", \"date_sk_date\"),\n",
        "    fact_payments_dw.date == F.col(\"date_sk_date\"),\n",
        "    how=\"left\"\n",
        ").drop(\"date_sk_date\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q23HdMCYlaJW"
      },
      "outputs": [],
      "source": [
        "dim_time_renamed = dim_time.withColumnRenamed(\"date\", \"time_date\")\n",
        "\n",
        "fact_complaints_dw = complaints.join(\n",
        "    dim_customers.select(\"customer_sk\", \"CustomerID\"),\n",
        "    on=\"CustomerID\",\n",
        "    how=\"left\"\n",
        ").join(\n",
        "    dim_time_renamed,\n",
        "    complaints[\"DateOpened\"] == F.col(\"time_date\"),\n",
        "    how=\"left\"\n",
        ").drop(\"time_date\", \"CustomerID\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkmNvzgplaSb"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "fact_payments_dw = fact_payments.join(\n",
        "    dim_customers.select(\"customer_sk\", F.col(\"CustomerID\").alias(\"dim_CustomerID\")),\n",
        "    fact_payments.CustomerID == F.col(\"dim_CustomerID\"),\n",
        "    how=\"left\"\n",
        ").join(\n",
        "    dim_time.withColumnRenamed(\"date\", \"date_sk_date\"),\n",
        "    fact_payments.date == F.col(\"date_sk_date\"),\n",
        "    how=\"left\"\n",
        ").drop(\"dim_CustomerID\", \"date_sk_date\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrGpnZXWlacr"
      },
      "outputs": [],
      "source": [
        "local_path = \"/home/jovyan/local_dw\"\n",
        "\n",
        "dim_customers.write.mode(\"overwrite\").parquet(f\"{local_path}/dim_customers\")\n",
        "dim_time.write.mode(\"overwrite\").parquet(f\"{local_path}/dim_time\")\n",
        "\n",
        "fact_payments_dw.write.mode(\"overwrite\").parquet(f\"{local_path}/fact_payments_dw\")\n",
        "fact_complaints_dw.write.mode(\"overwrite\").parquet(f\"{local_path}/fact_complaints_dw\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
